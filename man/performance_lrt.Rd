% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performance_lrt.R
\name{performance_lrt}
\alias{performance_lrt}
\alias{test_likelihoodratio}
\alias{test_lrt}
\alias{performance_lrt.default}
\title{Likelihood-Ratio-Test for Model Comparison}
\usage{
performance_lrt(...)

test_likelihoodratio(...)

test_lrt(...)

\method{performance_lrt}{default}(..., estimator = "ML")
}
\arguments{
\item{...}{Multiple model objects.}

\item{estimator}{Applied when comparing regression models. Corresponds to the different estimators for the standard deviation of the errors. If \code{estimator="OLS"} (default), then it uses the same method as \code{anova(..., test="LRT")} implemented in base R, i.e., scaling by n-k (the unbiased OLS estimator) and using this estimator under the alternative hypothesis. If \code{estimator="ML"}, which is for instance used by \code{lrtest(...)} in package \pkg{lmtest}, the scaling is done by n (the biased ML estimator) and the estimator under the null hypothesis. In moderately large samples, the differences should be negligible, but it is possible that OLS would perform slightly better in small samples with Gaussian errors.}
}
\value{
A data frame, based on the results from \code{anova()}.
}
\description{
Compute Likelihood-Ratio-Test (LRT) for model comparison, which tests which model is a better (more likely) explanation of the data. Likelihood-Ratio-Test (LRT) gives usually somewhat close results (if not equivalent) to the commonly used Wald F-test (obtained by default with \code{anova(...)}). Maximum likelihood tests make stronger assumptions than method of moments tests like the F-test, and in turn are more efficient. Agresti (1990) suggests that you should use the LRT instead of the Wald test for small sample sizes or if the parameters are large. A "small" sample size is under about 30.
\itemize{
\item For regression models, this is similar to \code{anova(..., test="LRT")} or \code{lmtest::lrtest(...)}, depending on the estimator.
\item For \code{lavaan} models (SEM, CFA), the function calls \code{lavaan::lavTestLRT()}.
}
}
\details{
This only makes statistical sense if the models are nested, in which case the models must be ordered from largest (the encompassing model) to smallest.
}
\examples{
# Regression Models
m1 <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
m2 <- lm(mpg ~ wt + cyl + gear, data = mtcars)
m3 <- lm(mpg ~ wt + cyl, data = mtcars)

performance_lrt(m1, m2, m3, estimator = "ML") # Equivalent to lmtest::lrtest(m1, m2, m3)
performance_lrt(m1, m2, m3, estimator = "OLS") # Equivalent to anova(m1, m2, m3, test='LRT')

# Lavaan Models
if (require("lavaan")) {
  structure <- " visual  =~ x1 + x2 + x3
                 textual =~ x4 + x5 + x6
                 speed   =~ x7 + x8 + x9

                  visual ~~ textual + speed "
  m1 <- lavaan::cfa(structure, data = HolzingerSwineford1939)

  structure <- " visual  =~ x1 + x2 + x3
                 textual =~ x4 + x5 + x6
                 speed   =~ x7 + x8 + x9

                  visual ~~ 0 * textual + speed "
  m2 <- lavaan::cfa(structure, data = HolzingerSwineford1939)

  structure <- " visual  =~ x1 + x2 + x3
                 textual =~ x4 + x5 + x6
                 speed   =~ x7 + x8 + x9

                  visual ~~ 0 * textual + 0 * speed "
  m3 <- lavaan::cfa(structure, data = HolzingerSwineford1939)

  performance_lrt(m1, m2, m3)
}
}
\seealso{
\code{\link[=compare_performance]{compare_performance()}} to compare performance of many different models.
}
